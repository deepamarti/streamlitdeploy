{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources used\n",
    "* https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "* https://datascience.stackexchange.com/questions/65979/what-is-the-correct-way-to-call-keras-flow-from-directory-method\n",
    "* https://stackoverflow.com/questions/42443936/keras-split-train-test-set-when-using-imagedatagenerator\n",
    "* https://github.com/keras-team/keras/issues/5862#issuecomment-647559571\n",
    "* https://keras.io/api/preprocessing/image/\n",
    "* https://stackoverflow.com/questions/57092637/how-to-fit-keras-imagedatagenerator-for-large-data-sets-using-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/tkashif/.conda/envs/ti-feeds-bert/lib/python3.7/site-packages (3.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/tkashif/.conda/envs/ti-feeds-bert/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.16 in /home/tkashif/.conda/envs/ti-feeds-bert/lib/python3.7/site-packages (from matplotlib) (1.19.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/tkashif/.conda/envs/ti-feeds-bert/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/tkashif/.conda/envs/ti-feeds-bert/lib/python3.7/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/tkashif/.conda/envs/ti-feeds-bert/lib/python3.7/site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/tkashif/.conda/envs/ti-feeds-bert/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: six in /home/tkashif/.conda/envs/ti-feeds-bert/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/tkashif/.conda/envs/ti-feeds-bert/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pandas in /home/tkashif/.conda/envs/ti-feeds-bert/lib/python3.7/site-packages (1.1.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/tkashif/.conda/envs/ti-feeds-bert/lib/python3.7/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/tkashif/.conda/envs/ti-feeds-bert/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/tkashif/.conda/envs/ti-feeds-bert/lib/python3.7/site-packages (from pandas) (1.19.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/tkashif/.conda/envs/ti-feeds-bert/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/tkashif/.conda/envs/ti-feeds-bert/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: numpy in /home/tkashif/.conda/envs/ti-feeds-bert/lib/python3.7/site-packages (1.19.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/tkashif/.conda/envs/ti-feeds-bert/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F_Tomato', 'S_Strawberry', 'F_Mango', 'F_Orange', 'S_Banana', 'F_Tamarillo', 'S_Orange', 'S_Tomato', 'S_Lemon', 'S_Tamarillo', 'S_Lulo', 'F_Lemon', 'F_Lulo', 'S_Mango', 'F_Strawberry', 'F_Banana']\n"
     ]
    }
   ],
   "source": [
    "# define constants\n",
    "ORIGINAL_PARENT_DIR = './FRUIT-16K' # enter path to original dataset\n",
    "PREPROCESSED_PARENT_DIR = './FRUIT-16K-PREPROCESSED' # enter path to folder where you want the preprocessed data to go (code will create it)\n",
    "\n",
    "CLASSES = []\n",
    "for directory in os.listdir(ORIGINAL_PARENT_DIR):\n",
    "    path = os.path.join(ORIGINAL_PARENT_DIR, directory)\n",
    "    if os.path.isdir(path) and not directory.startswith('.'):\n",
    "        CLASSES.append(directory)\n",
    "print(CLASSES)\n",
    "\n",
    "# define hyper-parameters\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_HEIGHT = 224\n",
    "IMAGE_WIDTH = 224\n",
    "SEED = 42\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    img = load_img(path, target_size = (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "    img_arr = img_to_array(img)\n",
    "    return img_arr\n",
    "\n",
    "def get_images_df(path):\n",
    "    # walk through the path and create a dataframe\n",
    "    # that has one column for the path to the image\n",
    "    # and the other with the class name\n",
    "    images_data = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if not file.startswith('.'):\n",
    "                # add to dict [ image | class_name ]\n",
    "                class_name = root.split(os.sep)[-1]\n",
    "                image_path = os.path.join(root, file)\n",
    "                images_data.append({\n",
    "                    'image_path': image_path,\n",
    "                    'class': class_name\n",
    "                })\n",
    "    df = pd.DataFrame(images_data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_train_test_data(x_train, x_test, y_train, y_test, classes, save_path): \n",
    "    # create the train and test folders\n",
    "    train_path = os.path.join(save_path, 'train')\n",
    "    test_path = os.path.join(save_path, 'test')\n",
    "    os.mkdir(train_path)\n",
    "    os.mkdir(test_path)\n",
    "        \n",
    "    # for each class, make a subfolder\n",
    "    for class_name in classes:\n",
    "        os.mkdir(os.path.join(train_path, class_name))\n",
    "        os.mkdir(os.path.join(test_path, class_name))\n",
    "    \n",
    "    # transfer files from dataframe image path to the appropriate\n",
    "    # subfolder in save_path (sub folders based on class name)\n",
    "    # also create x_train_final and x_test_final which will\n",
    "    # store pixels of image\n",
    "    x_train_final = []\n",
    "    x_test_final = []\n",
    "    for x_val, y_val in zip(x_train, y_train):\n",
    "        new_path = os.path.join(train_path, y_val)\n",
    "        shutil.copy(x_val, new_path)\n",
    "        filename = x_val.split(os.sep)[-1]\n",
    "        img_arr = read_image(os.path.join(new_path, filename))\n",
    "        x_train_final.append(img_arr)\n",
    "    for x_val, y_val in zip(x_test, y_test):\n",
    "        new_path = os.path.join(test_path, y_val)\n",
    "        shutil.copy(x_val, new_path)\n",
    "        filename = x_val.split(os.sep)[-1]\n",
    "        img_arr = read_image(os.path.join(new_path, filename))\n",
    "        x_test_final.append(img_arr)\n",
    "    \n",
    "    return np.asarray(x_train_final), np.asarray(x_test_final), y_train, y_test\n",
    "        \n",
    "def transfer_data(original_dir, new_dir, classes, test_size):\n",
    "    # get the images as a dataframe\n",
    "    # this dataframe has two columns, one with\n",
    "    # the path to the image in original_dir and one with\n",
    "    # the class name\n",
    "    original_df = get_images_df(original_dir)\n",
    "    \n",
    "    # split the df into train and test\n",
    "    x, y = original_df['image_path'], original_df['class']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 42, test_size = test_size)\n",
    "    \n",
    "    # create the new_dir folder\n",
    "    if os.path.exists(new_dir):\n",
    "        shutil.rmtree(new_dir)\n",
    "    os.mkdir(new_dir)\n",
    "    \n",
    "    # transfer all the data from original_df to new_dir\n",
    "    # with the appropriate formatting and get back the\n",
    "    # split with the x arrays having the pixels associated\n",
    "    # with the images and the y arrays having the label\n",
    "    x_train, x_test, y_train, y_test = create_train_test_data(x_train, x_test, y_train, y_test, classes, save_path = new_dir)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = transfer_data(ORIGINAL_PARENT_DIR, PREPROCESSED_PARENT_DIR, classes = CLASSES, test_size = TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with train image generator\n",
      "done with fit\n",
      "Found 12800 images belonging to 16 classes.\n",
      "Found 3200 images belonging to 16 classes.\n",
      "done with flow\n"
     ]
    }
   ],
   "source": [
    "# augment and preprocess the training data\n",
    "train_image_data_generator = ImageDataGenerator(rescale = 1./255, rotation_range=30,\n",
    "                                          zoom_range=0.15, width_shift_range=0.2,\n",
    "                                          height_shift_range=0.2, shear_range=0.15,\n",
    "                                          horizontal_flip=True, fill_mode=\"nearest\")\n",
    "print(\"done with train image generator\")\n",
    "\n",
    "# fit the train_image_data_generator to the train set\n",
    "# only run this line of code if featurewise_center or featurewise_std_normalization or zca_whitening set to True\n",
    "# train_image_data_generator.fit(x_train)\n",
    "print(\"done with fit\")\n",
    "\n",
    "# do NOT augment the testing data\n",
    "test_image_data_generator = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "\n",
    "# create the training generator and the testing generator from their respective folders\n",
    "train_generator = train_image_data_generator.flow_from_directory(os.path.join(PREPROCESSED_PARENT_DIR, 'train'), \n",
    "                                                                 target_size = (IMAGE_HEIGHT, IMAGE_WIDTH), \n",
    "                                                                 classes = CLASSES, batch_size = BATCH_SIZE, \n",
    "                                                                 shuffle = True, seed = SEED)\n",
    "\n",
    "#print(PREPROCESSED_PARENT_DIR)\n",
    "\n",
    "\n",
    "test_generator = test_image_data_generator.flow_from_directory(os.path.join(PREPROCESSED_PARENT_DIR, 'test'), \n",
    "                                                               target_size = (IMAGE_HEIGHT, IMAGE_WIDTH), \n",
    "                                                               classes = CLASSES, batch_size = BATCH_SIZE, \n",
    "                                                               shuffle = True, seed = SEED)\n",
    "\n",
    "print(\"done with flow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.63485050201416\n"
     ]
    }
   ],
   "source": [
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few potentially useful links/notes for the ML team\n",
    "* https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator (check out the Example of using `.flow_from_directory(directory)` section) for how (I think) you can use the fit function with generators)\n",
    "* You can access the mapping from class to indices through `train_generator.class_indices` or `train_generator.class_indices`\n",
    "* https://stackoverflow.com/questions/61864244/how-to-avoid-augmenting-data-in-validation-split-of-keras-imagedatagenerator\n",
    "* https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/\n",
    "* https://towardsdatascience.com/keras-data-generators-and-how-to-use-them-b69129ed779c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that the class index mapping are the same (should always be the case)\n",
    "print(test_generator.class_indices == train_generator.class_indices)\n",
    "print(train_generator.class_indices)\n",
    "print(len(train_generator.class_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    img, label = test_generator.next()\n",
    "    print(label[0])\n",
    "    plt.imshow(array_to_img(img[0]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    img, label = train_generator.next()\n",
    "    print(img.shape)\n",
    "    print(label[0])\n",
    "    plt.imshow(array_to_img(img[0]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import tensorflow as tf\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(224,224,3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.40))\n",
    "model.add(Dense(len(train_generator.class_indices), activation='softmax'))\n",
    "\n",
    "print(len(train_generator.class_indices))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "model.fit(train_generator,\n",
    "          batch_size=32,\n",
    "          epochs=750,\n",
    "          verbose=1,\n",
    "          validation_data=test_generator,\n",
    "          callbacks=[callback])\n",
    "\n",
    "score = model.evaluate(test_generator, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "img, label = train_generator.next()\n",
    "print(label[0])\n",
    "print(img[0].shape)\n",
    "\n",
    "singleImage = img[0]\n",
    "singleImage = np.expand_dims(singleImage, axis = 0) # Note that this is done because the model is trained on batches of images. \n",
    "print(singleImage.shape) # But when we are passing only 1 image our tensor size is only (224,224,3).\n",
    "test = model.predict(singleImage) # What we really want to pass in is (BATCH_SIZE,224,224,3), in this case the batch is 1. \n",
    "\n",
    "test.shape\n",
    "print(test)\n",
    "\n",
    "np.argmax(test) # This is done to get the array index of the highest probability output since we are using softmax. \n",
    "\n",
    "plt.imshow(img[0])\n",
    "plt.show()\n",
    "\n",
    "print(\"Prediction: \",(CLASSES[np.argmax(test)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
