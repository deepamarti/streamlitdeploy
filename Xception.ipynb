{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12800 images belonging to 16 classes.\n",
      "Found 3200 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set the seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Preprocess data (get all of the pixel values between 1 and 0, also called scaling/normalization)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Setup the train and test directories\n",
    "train_dir = \"FRUIT-16K-PREPROCESSED/train/\" # 80% of FRUIT-16K\n",
    "test_dir = \"FRUIT-16K-PREPROCESSED/test/\" # 20% of FRUIT-16K\n",
    "\n",
    "# Import data from directories and turn it into batches\n",
    "train_data = train_datagen.flow_from_directory(train_dir,\n",
    "                                               batch_size=32,\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               seed=42)\n",
    "\n",
    "valid_data = valid_datagen.flow_from_directory(test_dir,\n",
    "                                               batch_size=32,\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = './model_5_callbacks'\n",
    "model_5_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after base_model: (None, 7, 7, 2048)\n",
      "After GlobalAveragePooling2D(): (None, 2048)\n",
      "Epoch 1/5\n",
      "400/400 [==============================] - 34s 71ms/step - loss: 0.3575 - accuracy: 0.9249 - val_loss: 0.1181 - val_accuracy: 0.9750\n",
      "Epoch 2/5\n",
      "400/400 [==============================] - 28s 70ms/step - loss: 0.0714 - accuracy: 0.9894 - val_loss: 0.0644 - val_accuracy: 0.9872\n",
      "Epoch 3/5\n",
      "400/400 [==============================] - 28s 69ms/step - loss: 0.0403 - accuracy: 0.9951 - val_loss: 0.0439 - val_accuracy: 0.9941\n",
      "Epoch 4/5\n",
      "400/400 [==============================] - 30s 74ms/step - loss: 0.0260 - accuracy: 0.9977 - val_loss: 0.0353 - val_accuracy: 0.9944\n",
      "Epoch 5/5\n",
      "400/400 [==============================] - 28s 69ms/step - loss: 0.0184 - accuracy: 0.9983 - val_loss: 0.0306 - val_accuracy: 0.9937\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.xception.Xception(include_top=False, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(224, 224, 3), name=\"input_layer\")\n",
    "\n",
    "x = base_model(inputs)\n",
    "print(f\"Shape after base_model: {x.shape}\")\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
    "print(f\"After GlobalAveragePooling2D(): {x.shape}\")\n",
    "\n",
    "outputs = tf.keras.layers.Dense(16, activation=\"softmax\", name=\"output_layer\")(x)\n",
    "\n",
    "model_5 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model_5.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "history_5 = model_5.fit(train_data,\n",
    "                        epochs=5,\n",
    "                        validation_data=valid_data,\n",
    "                        validation_steps=len(valid_data),\n",
    "                        callbacks=[model_5_checkpoint_callback])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fb1492e6def891308ecbc0d3c1e81a09a0349f9b8052fb76570664c80f1546db"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tf-gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
